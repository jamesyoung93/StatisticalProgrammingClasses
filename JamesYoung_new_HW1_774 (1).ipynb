{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFS 774 Summer 2020 Assignment 1\n",
    "## Due 6/4/2020 + one-week grace period\n",
    "## In this assignment, you need to finish 3 different tasks. These tasks are not related. I provide code skeleton for these tasks. Wherever you see \"Your code here\", you need to add your code. \n",
    "## Please run your code and submit your notebook with the outputs to assignment 1 dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'James Young' #please type your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Implement the function list_ele_idx(li). \n",
    "The argument of the function is a list, li.The return value of the function should be a list of tuples. Each tuple includes an element in the list li and the index of the element. For example, if you have a list of two string [\"DSU\",\"MSA\"], this function should return a list of tuples [(\"DSU\",0), (\"MSA\",1)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_ele_idx(li):\n",
    "    index = 0 # index\n",
    "    lis = [] # initialze a list; you need to add a tuple that includes an element and its index to this list\n",
    "    for x in li:\n",
    "        lis.append((x, li.index(x))) #, li.index(x)\n",
    "     #lis = # Your code here. You can use a \"for\" loop to read items in li and add (item,index)tuples to the list lis\n",
    "    return lis # return a list of tuples\n",
    "\n",
    "#It appears that this can be done without the need for \"index = 0\" and achieve the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- task 1 test cases----------------\n",
      "[(5, 0), (3, 1), (2, 2), (6, 3)]\n"
     ]
    }
   ],
   "source": [
    "# I have written a test case for task 1\n",
    "print('---------------- task 1 test cases----------------')\n",
    "print(list_ele_idx([5,3,2,6])) # you code should output: [(5, 0), (3, 1), (2, 2), (6, 3)]\n",
    "\n",
    "#Looks right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the function reverse_key_value(dict1)\n",
    "This function takes a dictionary as its argument. A example of such dictionary can be:\n",
    "\n",
    "{“John”: “A”, “Sarah”: “A”, “Karen”: “B”, “Ken”: “C”}\n",
    "\n",
    "This function needs to reverse each key/value pair in dict1 and returns a dictionary dict2 that includes the reversed key/value pairs:\n",
    "\n",
    "{“A”:[“John”, “Sarah”], “B”:[“Karen”], “C”:[“Ken”]}\n",
    "\n",
    "In Python, a dictionary includes key-value pairs. The keys must be unique, but we can can have duplicate values. In the example above, two students “John” and “Sarah” both got “A”. Hence, when you reverse the key/value pairs, the keys in the new dictinary dict2 include the grades (\"A\", \"B\", and \"C\"), and the values need to be lists. For example, the key “A” corresponds to a list that includes two students “John” and “Sarah” because both John and Sarah got an A, while the key \"B\" corrsponds to a list with one element \"Karen\". You can assume that the values in the dictionary are hashable, i.e., they can be used as keys in the reversed dictionary dict2. As we discussed in the python tutoral, numbers, strings and tuples are hashable, while lists, dictionaries, and objects are un-hashable since they are mutable.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_key_value(dict1):\n",
    "    dict2 = {} # initialize an empty list.\n",
    "    #for k,v in dict1.items()# Your code here - use for k,v in dict1.items() to read the key values pair and then reverse them and add to dict2\n",
    "    for (k, v) in dict1.items():\n",
    "        if v in dict2:\n",
    "            dict2[v].append(k)\n",
    "        else:\n",
    "            dict2[v]=[k]  \n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- task 2 test cases----------------\n",
      "{'A': ['John', 'Sarah'], 'B': ['Karen'], 'C': ['Ken']}\n"
     ]
    }
   ],
   "source": [
    "# Test case for task 2\n",
    "print('---------------- task 2 test cases----------------')\n",
    "print(reverse_key_value({\"John\": \"A\", \"Sarah\": \"A\", \"Karen\": \"B\", \"Ken\": \"C\"}))# should print {'A': ['Sarah', 'John'], 'C': ['Ken'], 'B': ['Karen']}\n",
    "\n",
    "#Looks Right with the exception that john precedes sarah for new key \"A\" due to the order that k,v pairs were fed into the for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (Word Count). \n",
    "Please first download wordcount_data.zip from assignment 1 folder on D2L and unzip it to a folder called “wordcount_data” and add this folder to your ipython notebook working directory. In this folder, you should see three text files news1.txt, news2.txt and news3.txt. For each file, we want to find the words in the file and then count how many times each word appears in the file. Then we combine the results and count how many times each word appears in the folder/directory. For instance, the word “jpmorgan” appears 3 times in news1.txt and 3 times in news2.txt and does not appear in news3.txt; therefore, this word “jpmorgan” appear 3+3+0 =6 times in the folder. We will do this step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1. Download NLTK, python's naturual language processing package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\James\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # when you run this line of code for the first time, the nltk package will be downloaded. You will see\n",
    "                       # a pop-up window and click download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have implemented this function tokensize. It takes a string as a input and splits this string into a list of words (i.e. tokens).\n",
    "# please run this function\n",
    "def tokenize(s):\n",
    "    tokens = [] # initialize the output list\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    import string  \n",
    "    tokens1 = []\n",
    "    for token in tokens:\n",
    "        if token not in string.punctuation: # remove tokens that are punctuations\n",
    "            tokens1.append(token)\n",
    "    return tokens1 # return a list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2. Implement the function, count_list(li)\n",
    "\n",
    "This method counts how many times each element appears in the list. It outputs a dictionary. Each key-value pair show a list element and its number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_list(li):\n",
    "    dc = {}\n",
    "    for x in li:\n",
    "       # if \"test\" in wordFreqDic:\n",
    "        if not x in dc:\n",
    "            #add this item as a key to dc and the value of the key = 1 (please see the dictionary section of the tutorial for how you can add a key-value pair (i.e., an item) to a dictionary )\n",
    "            dc[x] = 1\n",
    "            #dict['key3'] = 'Geeks'\n",
    "        else: # this item is already a key in the dictionary\n",
    "            #the value of the key will be incremented by 1\n",
    "            dc[x] = dc.get(x) +1\n",
    "            \n",
    "    # Your code here to do wordcount for each element in the list\n",
    "    return dc\n",
    "#This is how I chose to do it, and it appears to work. Again the order is different but key, value pairs are correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test cases for the method count_list() -------\n",
      "{1: 2, 3: 3, 2: 1}\n",
      "{'a': 1, 'b': 3, ' ': 2}\n"
     ]
    }
   ],
   "source": [
    "# test case for task 3.2\n",
    "print(\"------ test cases for the method count_list() -------\")\n",
    "print(count_list([1, 3, 2, 1, 3, 3])) #output: {1: 2, 2: 1, 3: 3}\n",
    "print(count_list(['a', 'b', ' ', ' ', 'b', 'b'])) #output: {'a': 1, 'b': 3, ' ': 2} - The order of the keys does not matter'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3. Implement the function wordcount_file(file_path)\n",
    "You need to implement the function wordcount_file. This function take a file with its path as the argument and outputs a dictitonary. Each key in the dictionary is a unique word, and its value is the count of the word in the file. Within this function, you need to write code to lowercase all words read from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount_file(file_path):\n",
    "    s = \"\"\n",
    "    words = [] \n",
    "    dc = {}\n",
    "    f = open(file_path, 'r')\n",
    "    s = f.read() # this read function will read each file as a string\n",
    "    words = tokenize(s) # call the tokenize method defined previously and split the string into words\n",
    "    \n",
    "    # Your code here. The list \"words\" may contain words in both uppercase and lowercase. Your code here to lowercase each word in the list. \n",
    "    #modified from https://repl.it/repls/GreenFaroffFormulas#main.py\n",
    "    for i in range(len(words)):\n",
    "          words[i] = words[i].lower()\n",
    "    dc = count_list(words) # Now, the variable words is a list that includes lowercase words. You call the count_list function you implemented previous to obtain a dictionary\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jpmorgan': 3, 'chase': 1, 'on': 3, 'wednesday': 1, 'reported': 2, 'an': 2, 'unexpected': 1, 'drop': 1, 'in': 5, 'profit': 4, 'during': 1, 'a': 9, 'sluggish': 1, 'fourth': 2, 'quarter': 2, 'the': 17, 'bank': 4, 'said': 1, 'its': 1, 'earnings': 1, 'fell': 2, '7': 1, 'percent': 4, 'to': 3, '4.9': 1, 'billion': 7, 'or': 3, '1.19': 1, 'share': 3, 'from': 2, '5.6': 1, '1.30': 1, 'period': 1, 'year': 1, 'earlier': 1, 'most': 1, 'recent': 1, 'results': 1, 'short': 1, 'of': 5, '1.31': 1, 'expected': 1, 'by': 6, 'analysts': 2, 'surveyed': 1, 'thomson': 1, 'reuters': 1, 'net': 1, 'revenue': 2, 'at': 1, 'dropped': 1, '3': 1, '22.5': 1, '2013': 1, 'so-called': 1, 'managed': 1, 'basis': 2, 'was': 2, '23.55': 1, 'slightly': 1, 'below': 1, '23.6': 1, 'anticipated': 1, '’': 2, 's': 2, 'shares': 1, 'were': 1, 'down': 1, '4': 1, 'midmorning': 1, 'trading': 1, 'for': 2, '2014': 1, 'as': 2, 'whole': 1, '21.8': 1, '21': 1, 'increase': 1, 'and': 1, 'highest': 1, 'ever': 1, 'annual': 1, 'company': 2, 'quarterly': 1, 'hurt': 1, '900': 1, 'million': 1, 'new': 1, 'legal': 2, 'expenses': 1, '1.1': 1, 'pretax': 1, 'prepared': 1, 'settle': 1, 'investigation': 1, 'into': 1, 'manipulation': 1, 'foreign': 1, 'currency': 1, 'markets': 1, 'big': 2, 'banks': 1, 'these': 1, 'are': 1, 'latest': 1, 'costs': 1, 'being': 1, 'absorbed': 1, 'wake': 1, 'financial': 1, 'crisis': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n{'jpmorgan': 3,\\n 'chase': 1,\\n 'on': 3,\\n 'wednesday': 1,\\n 'reported': 2,\\n 'an': 2,\\n 'unexpected': 1,\\n 'drop': 1,\\n 'in': 5,\\n 'profit': 4,\\n 'during': 1,\\n 'a': 9,\\n 'sluggish': 1,\\n 'fourth': 2,\\n 'quarter': 2,\\n 'the': 17,\\n 'bank': 4,\\n 'said': 1,\\n 'its': 1,\\n 'earnings': 1,\\n 'fell': 2,\\n '7': 1,\\n 'percent': 4,\\n 'to': 3,\\n '4.9': 1,\\n 'billion': 7,\\n 'or': 3,\\n '1.19': 1,\\n 'share': 3,\\n 'from': 2,\\n '5.6': 1,\\n '1.30': 1,\\n 'period': 1,\\n 'year': 1,\\n 'earlier': 1,\\n 'most': 1,\\n 'recent': 1,\\n 'results': 1,\\n 'short': 1,\\n 'of': 5,\\n '1.31': 1,\\n 'expected': 1,\\n 'by': 6,\\n 'analysts': 2,\\n 'surveyed': 1,\\n 'thomson': 1,\\n 'reuters': 1,\\n 'net': 1,\\n 'revenue': 2,\\n 'at': 1,\\n 'dropped': 1,\\n '3': 1,\\n '22.5': 1,\\n '2013': 1,\\n 'so-called': 1,\\n 'managed': 1,\\n 'basis': 2,\\n 'was': 2,\\n '23.55': 1,\\n 'slightly': 1,\\n 'below': 1,\\n '23.6': 1,\\n 'anticipated': 1,\\n '’': 2,\\n 's': 2,\\n 'shares': 1,\\n 'were': 1,\\n 'down': 1,\\n '4': 1,\\n 'midmorning': 1,\\n 'trading': 1,\\n 'for': 2,\\n '2014': 1,\\n 'as': 2,\\n 'whole': 1,\\n '21.8': 1,\\n '21': 1,\\n 'increase': 1,\\n 'and': 1,\\n 'highest': 1,\\n 'ever': 1,\\n 'annual': 1,\\n 'company': 2,\\n 'quarterly': 1,\\n 'hurt': 1,\\n '900': 1,\\n 'million': 1,\\n 'new': 1,\\n 'legal': 2,\\n 'expenses': 1,\\n '1.1': 1,\\n 'pretax': 1,\\n 'prepared': 1,\\n 'settle': 1,\\n 'investigation': 1,\\n 'into': 1,\\n 'manipulation': 1,\\n 'foreign': 1,\\n 'currency': 1,\\n 'markets': 1,\\n 'big': 2,\\n 'banks': 1,\\n 'these': 1,\\n 'are': 1,\\n 'latest': 1,\\n 'costs': 1,\\n 'being': 1,\\n 'absorbed': 1,\\n 'wake': 1,\\n 'financial': 1,\\n 'crisis': 1}\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case for task 3.3.\n",
    "print(wordcount_file(\"wordcount_data/news1.txt\"))\n",
    "# your output should be - the order of the keys does not matter:\n",
    "\"\"\"\n",
    "{'jpmorgan': 3,\n",
    " 'chase': 1,\n",
    " 'on': 3,\n",
    " 'wednesday': 1,\n",
    " 'reported': 2,\n",
    " 'an': 2,\n",
    " 'unexpected': 1,\n",
    " 'drop': 1,\n",
    " 'in': 5,\n",
    " 'profit': 4,\n",
    " 'during': 1,\n",
    " 'a': 9,\n",
    " 'sluggish': 1,\n",
    " 'fourth': 2,\n",
    " 'quarter': 2,\n",
    " 'the': 17,\n",
    " 'bank': 4,\n",
    " 'said': 1,\n",
    " 'its': 1,\n",
    " 'earnings': 1,\n",
    " 'fell': 2,\n",
    " '7': 1,\n",
    " 'percent': 4,\n",
    " 'to': 3,\n",
    " '4.9': 1,\n",
    " 'billion': 7,\n",
    " 'or': 3,\n",
    " '1.19': 1,\n",
    " 'share': 3,\n",
    " 'from': 2,\n",
    " '5.6': 1,\n",
    " '1.30': 1,\n",
    " 'period': 1,\n",
    " 'year': 1,\n",
    " 'earlier': 1,\n",
    " 'most': 1,\n",
    " 'recent': 1,\n",
    " 'results': 1,\n",
    " 'short': 1,\n",
    " 'of': 5,\n",
    " '1.31': 1,\n",
    " 'expected': 1,\n",
    " 'by': 6,\n",
    " 'analysts': 2,\n",
    " 'surveyed': 1,\n",
    " 'thomson': 1,\n",
    " 'reuters': 1,\n",
    " 'net': 1,\n",
    " 'revenue': 2,\n",
    " 'at': 1,\n",
    " 'dropped': 1,\n",
    " '3': 1,\n",
    " '22.5': 1,\n",
    " '2013': 1,\n",
    " 'so-called': 1,\n",
    " 'managed': 1,\n",
    " 'basis': 2,\n",
    " 'was': 2,\n",
    " '23.55': 1,\n",
    " 'slightly': 1,\n",
    " 'below': 1,\n",
    " '23.6': 1,\n",
    " 'anticipated': 1,\n",
    " '’': 2,\n",
    " 's': 2,\n",
    " 'shares': 1,\n",
    " 'were': 1,\n",
    " 'down': 1,\n",
    " '4': 1,\n",
    " 'midmorning': 1,\n",
    " 'trading': 1,\n",
    " 'for': 2,\n",
    " '2014': 1,\n",
    " 'as': 2,\n",
    " 'whole': 1,\n",
    " '21.8': 1,\n",
    " '21': 1,\n",
    " 'increase': 1,\n",
    " 'and': 1,\n",
    " 'highest': 1,\n",
    " 'ever': 1,\n",
    " 'annual': 1,\n",
    " 'company': 2,\n",
    " 'quarterly': 1,\n",
    " 'hurt': 1,\n",
    " '900': 1,\n",
    " 'million': 1,\n",
    " 'new': 1,\n",
    " 'legal': 2,\n",
    " 'expenses': 1,\n",
    " '1.1': 1,\n",
    " 'pretax': 1,\n",
    " 'prepared': 1,\n",
    " 'settle': 1,\n",
    " 'investigation': 1,\n",
    " 'into': 1,\n",
    " 'manipulation': 1,\n",
    " 'foreign': 1,\n",
    " 'currency': 1,\n",
    " 'markets': 1,\n",
    " 'big': 2,\n",
    " 'banks': 1,\n",
    " 'these': 1,\n",
    " 'are': 1,\n",
    " 'latest': 1,\n",
    " 'costs': 1,\n",
    " 'being': 1,\n",
    " 'absorbed': 1,\n",
    " 'wake': 1,\n",
    " 'financial': 1,\n",
    " 'crisis': 1}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4. Implement the function wordcount_directory(directory) \n",
    "This functions does wordcount for words in a directory that may include a number of files. It takes a directory as the argument and returns a dictionary with words as keys and wordcounts as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def wordcount_directory(directory):\n",
    "    dc= {}\n",
    "    #read filenames in the directory\n",
    "        # r=>root, d=>directories, f=>files\n",
    "    files_in_dir = []\n",
    "    for r, d, f in os.walk(directory):\n",
    "        for item in f:\n",
    "              if '.txt' in item:\n",
    "                    files_in_dir.append(os.path.join(r, item))\n",
    "    for path in files_in_dir:\n",
    "        #set path to be directory+\"/\"+filename\n",
    "        #call the function wordcount_file with path as the argument to get the dictionary dict1 for each file\n",
    "        dict1 = wordcount_file(path)\n",
    "        for k,v in dict1.items(): # for each key value pair in the dictionary dict1\n",
    "             if not k in dc:\n",
    "                dc.update({k:v})\n",
    "             else:\n",
    "                dc[k] = dc.get(k) + v\n",
    "    return dc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jpmorgan': 6, 'chase': 4, 'on': 21, 'wednesday': 2, 'reported': 5, 'an': 5, 'unexpected': 1, 'drop': 1, 'in': 26, 'profit': 5, 'during': 3, 'a': 21, 'sluggish': 1, 'fourth': 5, 'quarter': 9, 'the': 69, 'bank': 9, 'said': 2, 'its': 2, 'earnings': 4, 'fell': 3, '7': 2, 'percent': 4, 'to': 26, '4.9': 3, 'billion': 20, 'or': 6, '1.19': 3, 'share': 5, 'from': 7, '5.6': 2, '1.30': 1, 'period': 1, 'year': 6, 'earlier': 1, 'most': 1, 'recent': 3, 'results': 3, 'short': 1, 'of': 34, '1.31': 2, 'expected': 1, 'by': 13, 'analysts': 3, 'surveyed': 1, 'thomson': 1, 'reuters': 1, 'net': 9, 'revenue': 9, 'at': 6, 'dropped': 1, '3': 2, '22.5': 1, '2013': 2, 'so-called': 1, 'managed': 1, 'basis': 3, 'was': 11, '23.55': 1, 'slightly': 1, 'below': 4, '23.6': 2, 'anticipated': 1, '’': 2, 's': 2, 'shares': 1, 'were': 5, 'down': 4, '4': 2, 'midmorning': 1, 'trading': 1, 'for': 12, '2014': 1, 'as': 10, 'whole': 1, '21.8': 1, '21': 1, 'increase': 2, 'and': 24, 'highest': 1, 'ever': 1, 'annual': 1, 'company': 4, 'quarterly': 1, 'hurt': 1, '900': 1, 'million': 2, 'new': 1, 'legal': 7, 'expenses': 2, '1.1': 3, 'pretax': 1, 'prepared': 1, 'settle': 1, 'investigation': 1, 'into': 2, 'manipulation': 1, 'foreign': 1, 'currency': 1, 'markets': 2, 'big': 2, 'banks': 1, 'these': 3, 'are': 3, 'latest': 1, 'costs': 2, 'being': 1, 'absorbed': 1, 'wake': 1, 'financial': 1, 'crisis': 1, 'banking': 1, 'giant': 1, 'used': 1, 'be': 5, 'golden': 1, 'child': 1, 'wall': 1, 'street': 1, 'but': 1, 'disappointed': 1, 'investors': 1, 'reporting': 1, 'profits': 2, 'that': 5, 'forecasts': 1, '--': 1, 'largely': 1, 'due': 1, 'increased': 2, 'ceo': 1, 'jamie': 1, 'dimon': 2, 'continues': 1, 'show': 2, 'resentment': 1, 'about': 2, 'how': 2, 'much': 1, 'scrutiny': 1, 'his': 1, 'has': 3, 'come': 1, 'under': 2, 'various': 1, 'government': 1, 'agencies': 1, 'conference': 1, 'call': 2, 'with': 5, 'reporters': 1, '``': 2, 'assault': 1, \"''\": 2, 'regulators': 2, 'when': 1, 'asked': 1, 'more': 2, 'details': 1, 'he': 1, 'responded': 1, 'saying': 1, 'you': 5, \"'ve\": 5, 'got': 1, 'kidding': 1, 'me': 1, 'sure': 1, 'is': 4, 'hardly': 1, 'struggling': 1, 'still': 1, 'ago': 1, 'translated': 1, 'expecting': 1, 'weighed': 1, 'along': 1, 'some': 2, 'rivals': 1, 'been': 1, 'accused': 1, 'federal': 1, 'around': 1, 'world': 1, 'manipulating': 1, 'foreign-exchange': 1, 'settled': 1, 'those': 2, 'charges': 1, 'november': 1, '2': 2, 'well': 3, 'there': 1, 'concerns': 1, 'throughout': 2, 'industry': 1, 'regulations': 1, 'calls': 1, 'boost': 1, 'capital': 3, 'requirements': 1, 'will': 3, 'make': 1, 'firms': 1, 'far': 1, 'less': 1, 'profitable': 1, 'future': 1, 'marianne': 1, 'lake': 1, 'cfo': 1, 'thank': 1, 'operator': 1, 'good': 1, 'morning': 1, 'everyone': 1, 'i': 3, \"'m\": 2, 'going': 3, 'take': 1, 'through': 2, 'presentation': 5, 'which': 5, 'available': 1, 'our': 6, 'web': 1, 'site': 1, 'please': 1, 'refer': 1, 'disclaimer': 1, 'regarding': 1, 'forward-looking': 1, 'statements': 1, 'back': 1, 'starting': 1, 'page': 9, '1': 2, 'firm': 5, 'income': 5, 'eps': 5, 'return': 3, 'tangible': 3, 'common': 3, 'equity': 4, '11': 1, 'included': 2, 'total': 2, 'expense': 5, 'approximately': 3, 'after': 1, 'tax': 1, 'large': 1, 'part': 1, 'incremental': 2, 'amount': 1, 'fx': 1, 'we': 9, 'go': 2, 'out': 1, 'other': 1, 'notable': 1, 'items': 2, 'your': 1, 'reference': 1, 'impact': 5, 'here': 3, 'front': 1, 'they': 1, 'contributed': 1, 'positive': 2, '0.12': 1, 'so': 2, 'adjusting': 1, 'gives': 1, '5.5': 1, '1.33': 1, 'reflecting': 1, 'solid': 1, 'core': 2, 'performance': 1, 'skip': 1, 'over': 1, \"'re\": 2, 'straight': 1, 'full-year': 1, 'record': 3, 'nearly': 2, '22': 1, '5.29': 1, '13': 1, '98': 1, 'excluding': 2, 'remains': 1, 'elevated': 1, '24': 1, '14': 1, 'can': 2, 'see': 2, 'bottom': 1, 'adjusted': 1, '58.4': 1, 'line': 3, 'guidance': 1, '650': 1, 'prior': 1, 'despite': 1, 'cost': 2, 'control': 1, 'continuing': 1, 'invest': 1, 'businesses': 3, 'final': 1, 'couple': 1, 'points': 2, 'loan': 1, 'growth': 1, 'strong': 1, '8': 1, 'year-on-year': 1, 'distributions': 2, '10': 1, 'including': 1, 'dividends': 4, '6': 1, 'turning': 1, \"'s\": 4, 'fully': 2, 'phased': 2, 'advanced': 1, 'cet1': 1, 'ratio': 4, '10.1': 1, 'flat': 2, 'last': 1, 'portfolio': 1, 'runoff': 1, 'offset': 1, 'risk-weighted': 1, 'assets': 1, 'predominantly': 1, 'driven': 1, 'higher': 1, 'counterparty': 1, 'credit': 1, 'risk': 1, 'terms': 1, '2015': 1, 'outlook': 1, 'expect': 1, 'add': 1, '50': 1, 'this': 4, 'similarly': 1, 'standardized': 1, 'not': 1, 'also': 2, 'remained': 1, '10.5': 1, 'slr': 2, 'improved': 1, '5.9': 1, 'given': 2, 'fsb': 1, 'proposal': 1, 'added': 1, 'best': 1, 'estimate': 1, 'tlac': 1, '15': 1, 'buffers': 1, 'refined': 1, 'rules': 1, 'finalized': 1, 'moving': 1, '5': 1, 'before': 1, 'move': 1, 'each': 2, 'changed': 1, 'preferred': 5, 'lines': 1, 'business': 1, 'continue': 1, 'however': 1, 'historically': 1, 'allocated': 1, 'stock': 1, 'interest': 1, 'contra': 2, 'corresponding': 1, 'corporate': 1, 'nii': 1, 'order': 1, 'have': 1, 'cleaner': 1, 'trends': 1, 'better': 1, 'peer': 1, 'comparability': 1, 'now': 1, 'presenting': 1, 'lobs': 1, 'particularly': 1, 'important': 1, 'increases': 1, 'issuance': 1, 'slide': 1, 'change': 2, 'methodology': 1, 'no': 1, 'firm-wide': 1, 'financials': 1, 'nor': 1, 'lob': 2, 'returns': 1, 'while': 1, 'overhead': 1, 'ratios': 1, 'improve': 1, 'additionally': 1, 'adjustment': 1, 'affects': 1, 'cib': 1, 'supplement': 1, 'all': 2, 'numbers': 1, 'periods': 1, 'consistently': 1, 'reflect': 1}\n"
     ]
    }
   ],
   "source": [
    "print(wordcount_directory(\"wordcount_data\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
